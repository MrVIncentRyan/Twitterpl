import tweepy
import time
import csv
from math import ceil
from tweepy import OAuthHandler
Â 
auth = OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_secret)
Â 
api = tweepy.API(auth)
slug = 
owner = 
Â Â Â Â 
Â 

def get_list_members(api, owner, slug):

	members = []

	# without this you only get the first 20 list members

	for page in tweepy.Cursor(api.list_members, owner, slug).items():

		members.append(page)

	# create a list containing all usernames

    return [ m.screen_name for m in members ]


    # create new CSV file and add column headings

    time.sleep(90) ## 90 second rest between api calls. The API allows 15 calls per 15 minutes so this is conservative


def create_csv(filename, usernames):

	csvfile = open(filename, 'w')

	c = csv.writer(csvfile)

	# write the header row for CSV file

	c.writerow( [ "name",

				"display_name",

				"bio",

				"followers_count",

				"following_count",

				"acct_created",

				"location",

				"timeline" ] )

	# add each member to the csv

	for name in usernames:

		user_info = get_userinfo(name)

		c.writerow( user_info )

	# close
	 and save the CSV

	csvfile.close()

def get_userinfo(name):

	# get all user data via a Tweepy API call

	user = api.get_user(screen_name = name)

	# create row data as a list

	user_info = [ name.encode('utf-8'),

				user.name.encode('utf-8'),

				user.description.encode('utf-8'),

				user.followers_count,

				user.friends_count,

				user.created_at,

				user.location.encode('utf-8') ]

	# send that one row back

	return user_info

def get_all_tweets(screen_name = name):


    #initialize a list to hold all the tweepy Tweets

    alltweets = []  

    

    #make initial request for most recent tweets (200 is the maximum allowed count)

    new_tweets = api.user_timeline(screen_name = screen_name,count=200)

    

    #save most recent tweets

    alltweets.extend(new_tweets)

    

    #save the id of the oldest tweet less one

    oldest = alltweets[-1].id - 1

    

    #keep grabbing tweets until there are no tweets left to grab

    while len(new_tweets) > 0:

        print ("getting tweets before %s" % (oldest))

        

        #all subsiquent requests use the max_id param to prevent duplicates

        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)

        

        #save most recent tweets

        alltweets.extend(new_tweets)

        

        #update the id of the oldest tweet less one

        oldest = alltweets[-1].id - 1

        

        print ("...%s tweets downloaded so far" % (len(alltweets)))

    

    #transform the tweepy tweets into a 2D array that will populate the csv 

    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode("utf-8")] for tweet in alltweets]

    

    #write the csv  

    with open('%s_tweets.csv' % screen_name, 'w') as f:

        writer = csv.writer(f)

        writer.writerow(["id","created_at","text"])

        writer.writerows(outtweets)

    

    pass

if __name__ == '__main__':

	main()
